{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68519a8d-2db3-4414-8357-954249738e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#pd.set_option('display.max_colwidth', -1)\n",
    "pd.set_option('display.max_rows',5000)\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe885baf-af43-45ac-a0a2-69aa24e08e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 =pd.read_csv(\"students_final2.csv\").copy()\n",
    "df2.loc[len(df2.index)] = ['anonim_mis',\"MIS463\",\"Aslı Sencer\",\"anonim_mis MIS463 dersini Aslı Sencer hocasından kesinlikle öneriyor.\",1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94302d29-b0cb-4626-b6b9-3a54f91ee02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.loc[df2['Text'].str.contains('hocasından şiddetle önermiyor.'), 'Text'] = \"-\"\n",
    "df2.loc[df2['Text'].str.contains('hocasından kesinlikle öneriyor.'), 'Text'] = \"-\"\n",
    "df2.loc[df2['Text'].str.contains('hocasından ne iyi ne kötü buluyor.'), 'Text'] = \"-\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c78dc74c-573f-4f6d-a6e4-e1bd8ad5b0e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Username</th>\n",
       "      <th>Lesson Name</th>\n",
       "      <th>Teacher Name</th>\n",
       "      <th>Text</th>\n",
       "      <th>Point</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>elif</td>\n",
       "      <td>SOC101</td>\n",
       "      <td>Ali Tuna Kuyucu</td>\n",
       "      <td>-</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Zeynep837</td>\n",
       "      <td>SOC101</td>\n",
       "      <td>Ali Tuna Kuyucu</td>\n",
       "      <td>-</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mrymsygili</td>\n",
       "      <td>SOC101</td>\n",
       "      <td>Ali Tuna Kuyucu</td>\n",
       "      <td>-</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cengin</td>\n",
       "      <td>SOC101</td>\n",
       "      <td>Ali Tuna Kuyucu</td>\n",
       "      <td>-</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tylerdurden</td>\n",
       "      <td>SOC101</td>\n",
       "      <td>Ali Tuna Kuyucu</td>\n",
       "      <td>-</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Username Lesson Name     Teacher Name Text  Point\n",
       "0         elif      SOC101  Ali Tuna Kuyucu    -    0.0\n",
       "1    Zeynep837      SOC101  Ali Tuna Kuyucu    -    0.0\n",
       "2   mrymsygili      SOC101  Ali Tuna Kuyucu    -    0.0\n",
       "3       cengin      SOC101  Ali Tuna Kuyucu    -    0.0\n",
       "4  tylerdurden      SOC101  Ali Tuna Kuyucu    -    0.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de0b6ef8-f5b5-456e-8089-c767b1d334c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df2[df2.Text != \"-\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0738ae5a-9bf9-4b2c-bb64-c91b5b4d27d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at dbmdz/bert-base-turkish-128k-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at dbmdz/bert-base-turkish-128k-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "import transformers as trf\n",
    "\n",
    "bert = trf.TFBertModel.from_pretrained('dbmdz/bert-base-turkish-128k-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f242de23-6a9d-42b3-9da2-de4622f951ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = trf.BertTokenizer.from_pretrained('dbmdz/bert-base-turkish-128k-uncased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9bcbaaaa-cd3a-4c3f-870e-c5e2df73d3b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens: ['[CLS]', 'inanılmaz', 'verimsiz', 'bir', 'deneme', 'yorumu', 'test', 'edilecek', '[SEP]']\n",
      "ids   : [2, 8890, 41824, 1947, 9222, 12742, 4429, 6728, 3]\n"
     ]
    }
   ],
   "source": [
    "txt = \"inanılmaz verimsiz bir deneme yorumu test edilecek\"\n",
    "## tokenize\n",
    "idx = tokenizer.encode(txt)\n",
    "print(\"tokens:\", tokenizer.convert_ids_to_tokens(idx))\n",
    "print(\"ids   :\", tokenizer.encode(txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a70ebe5-5aee-4c21-8317-e51da9072b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (1, 9, 768)\n"
     ]
    }
   ],
   "source": [
    "idx = np.array(idx)[None,:] \n",
    "embedding = bert(idx)  \n",
    "print(\"shape:\", embedding[0].shape) \n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab3ac5b9-ecf8-47ab-857f-56cd3e9c4287",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_competence = [\"Anlattığı konuya oldukça hakim.\",\"Oldukça ufuk açıcı bir ders\",\"Bu ders konuya dair oldukça öğreticiydi.\",\"Kesinlikle bu dersi alabileceğiniz en iyi hocalardan birisi.\",\"Her yönden çok donanımlı bir eğitmen. Öğrenci dostu olmasının yanında bilgili, bilgisini aktarmaya hevesli ve öğretmenlik motivasyonunu kaybetmemiş hocalardan.\",\"Okulun en tatlı ve en kültürlü hocasıdır.\", \"gayet ilgili ve anlatım konusunda da oldukça başarılı\",\"Dersleri hala büyük bir hevesle anlatıp ilginizi kaybetmemenizi sağlıyor.\",\"dersleri dinlerken hiç sıkıldığımı hatırlamıyorum\",\"Dersler esprili, komik ve eğlenceli geçiyor.\"]\n",
    "negative_competence = [\"Ders anlatımı hiç yetkin değil\",\"Anlattığı dersi takip etmekte çok zorlanıyorum ve bu ders takip edilemiyor\",\"Anlattıklarını kendi bile bilmiyor\",\"bu dersi bilhassa bu hocadan almamanin bi formulunu bulmanizi oneririm.\",\"kendisinden ders alınacak adam değildir.\",\"hayatımda gördüğm en sorumsuz insanlardan biri.\",\"Bir insan verdiği dersi nasıl bu kadar umursamaz aklım almıyor.\",\"ders videolarını ve slaytları ya çok geç yükler ya eksik yükler.\",\"Dersler asla takip edilemiyor\",\"discussionlar sıkıcı\",\"allah bu dersi alanlara sabır versin\",\"dünyanın en korkunç dersi\",\"tam anlamıyla hayatımı karartan bir ders oldu\"]\n",
    "student_friendly = [\"Dersleri eğlenceli geçer.\",\"İnanılmaz tatlı bir hoca\",\"Kendisiyle istediğimiz zamanda iletişimde bulunabiliyoruz.\",\"Maillere anında dönüyor.\",\"Oldukça güler yüzlü ve neşeli birisi.\",\"Ses tonu bile insanın içini ısıtıyor.\",\"Kimsenin sorusunu cevapsız bırakmadı.\",\"Tam anlamıyla öğrenci dostu.\",\" Derslerinde ve hatta pslerde kayıt aldı ve dönem boyunca tüm ders materyallerini bizimle paylaştı.\",\"kitabı gerekli bölümleri okuyorsunuz sonra yarın sınava giriyorsunuz ve AA geliyor\",\"Ne zaman neye ihtiyacım olsa erinmeden dinledi yardım etti.\",\"Her şeyini öğrenciler için feda edebilecek birisi tamamen mükemmellik abidesi\"]\n",
    "not_student_friendly = [\"Bu ders sayesinde sigaraya başladım.\",\"Neredeyse panik atak geçiriyordum.\",\"Sınav sonuçlarını asla zamanında açıklamaz\",\"Baya agrasif bir hoca\",\"Öğrenciye her türkü zorluk çıkartabilecek birisi.\",\"Her türlü mağduriyeti yaşarsınız.\",\"Tam bir cadıdır kendisi.\",\"diğer sectionların aksine katbekat zor sorar ve sınav ortalaması düşüktür.\",\"Notu kıt bir hoca bence.\",\"Seçmeme imkanı olan bir bölümdeyseniz yanından geçmeyin derim.\",\"almayın yani korkunç bi ders\",\" Sınav değerlendirmeleri biraz saçma\",\"notları kıt\",\"sizi mağdur etmenin mutlaka bir yolunu bulur\",\"öğrenciye tamamen düşman birisi\",\"bu dersi kesinlikle önermiyorum\"]\n",
    "good_english = [\"İnanılmaz akıcı bir ingilizceye sahip\",\"Derslerine konuşmasını dinlemek için bile gidilir.\",\"Derste söylediği cümleler gayet anlaşılabilir.\",\"Tam bir beyefendi\",\"Yurtdışında eğitim aldığı belli oluyor\",\"anlattığı ders anlaşılabilir ve oldukça akıcı\",\"türk aksanına yakın konuştuğu için dersleri anlaşılabilir\",\"tane tane konuşuyor\"]\n",
    "bad_english = [\"Ders esnasında söyledikleri hiç anlaşılmıyor.\",\"Çok kötü bir aksanı var.\",\"Derste söylenenlerden hiçbir şey anlayamıyorum.\",\"Telafuzu çok kötü.\",\"konuşmaya başladığı zaman insan direkt bunalıyor\",\"ben bu kadar yorucu şekilde konuşan birisini hiç görmedim\",\"bu adam nasıl native speaker anlamak güç\",\"dersten hiçbir şey anlaşılmıyor\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5cca2ad6-3872-4472-b12e-9b84d8328e8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 9, 768), dtype=float32, numpy=\n",
       "array([[[-0.52085036, -0.38367802, -2.135634  , ...,  0.13875636,\n",
       "          0.25557533,  0.45156914],\n",
       "        [ 0.15423784, -0.5098587 , -0.93862164, ..., -1.7609076 ,\n",
       "         -0.07611521, -0.80006295],\n",
       "        [-0.09277726, -0.00352648, -0.38873488, ..., -0.8360086 ,\n",
       "          1.1227279 , -0.10558483],\n",
       "        ...,\n",
       "        [-0.87440735, -0.6651399 , -0.7555843 , ..., -0.44479614,\n",
       "         -0.4471798 ,  0.38828442],\n",
       "        [-0.9165956 , -0.23888063, -1.616482  , ..., -0.7969353 ,\n",
       "          0.2658898 , -0.01221884],\n",
       "        [ 0.05425656, -1.0066826 , -0.9775546 , ..., -0.23505326,\n",
       "         -0.07000898,  0.03290154]]], dtype=float32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4dd7c21-31e9-4f9a-9007-56916f8130ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.52085036, -0.38367802, -2.135634  , ...,  0.13875636,\n",
       "         0.25557533,  0.45156914],\n",
       "       [ 0.15423784, -0.5098587 , -0.93862164, ..., -1.7609076 ,\n",
       "        -0.07611521, -0.80006295],\n",
       "       [-0.09277726, -0.00352648, -0.38873488, ..., -0.8360086 ,\n",
       "         1.1227279 , -0.10558483],\n",
       "       ...,\n",
       "       [-0.87440735, -0.6651399 , -0.7555843 , ..., -0.44479614,\n",
       "        -0.4471798 ,  0.38828442],\n",
       "       [-0.9165956 , -0.23888063, -1.616482  , ..., -0.7969353 ,\n",
       "         0.2658898 , -0.01221884],\n",
       "       [ 0.05425656, -1.0066826 , -0.9775546 , ..., -0.23505326,\n",
       "        -0.07000898,  0.03290154]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a =np.array(embedding[0][0])  #---> embedding of batch(here 1 sentence)\n",
    "a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "147fe1c3-fd5f-4185-a671-6f96799dfbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_embedding(txt):\n",
    "  idx = tokenizer.encode(txt,truncation=True) #creating tokens\n",
    "  idx = np.array(idx)[None,:] #converting 2d array\n",
    "\n",
    "  emb = bert(idx) #bert layer\n",
    "  hidden = np.array(emb[0][0]) #batch output of last_hidden_state\n",
    "\n",
    "  sent_emb = hidden.mean(0) # creating mean vector\n",
    "  return sent_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a920a2b3-398c-4853-a4a2-22d53458e44e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c77d0f662c34a7da8223ea8b767c941",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2832 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_sentences = 20000 #as I have limited computation power, this much sentences have been selected\n",
    "sent_matrix = np.array([bert_embedding(text) for text in tqdm(df['Text'][0:num_sentences])])\n",
    "sent_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00dff00-69ef-40ef-ba76-09f7f45fdea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_competence_emb = np.array([bert_embedding(t) for t in positive_competence])\n",
    "positive_competence_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3a560d-a19d-4bb1-9816-8bfcf7104240",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_competence_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72c1fb0-468c-4304-9357-c11fc368182d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0743ede4-7e63-4756-952a-aca091f0a4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in [positive_competence,negative_competence,student_friendly,not_student_friendly,good_english,bad_english]:\n",
    "  d_emb = np.array([bert_embedding(t) for t in d])\n",
    "  print('Cosine similarity of given samples: {}'.format(cosine_similarity(d_emb[0][None,:],d_emb[1][None,:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90689f8c-9a25-4e06-9ec3-4f0d4eb763e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_competence_emb = np.array([bert_embedding(t) for t in positive_competence])\n",
    "negative_competence_emb = np.array([bert_embedding(t) for t in negative_competence])\n",
    "student_friendly_emb = np.array([bert_embedding(t) for t in student_friendly])\n",
    "not_student_friendly_emb = np.array([bert_embedding(t) for t in not_student_friendly])\n",
    "good_english_emb = np.array([bert_embedding(t) for t in good_english])\n",
    "bad_english_emb = np.array([bert_embedding(t) for t in bad_english])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8423199-5124-4865-9258-13d160640223",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_score = pd.DataFrame(columns=['id','positive_competence','negative_competence','student_friendly','not_student_friendly','good_english','bad_english'])\n",
    "cosine_score['id'] = range(len(sent_matrix))\n",
    "cosine_score['positive_competence'] = cosine_similarity(sent_matrix,positive_competence_emb.mean(0)[None,:])\n",
    "cosine_score['negative_competence'] = cosine_similarity(sent_matrix,negative_competence_emb.mean(0)[None,:])\n",
    "cosine_score['student_friendly'] = cosine_similarity(sent_matrix,student_friendly_emb.mean(0)[None,:])\n",
    "cosine_score['not_student_friendly'] = cosine_similarity(sent_matrix,not_student_friendly_emb.mean(0)[None,:])\n",
    "cosine_score['good_english'] = cosine_similarity(sent_matrix,good_english_emb.mean(0)[None,:])\n",
    "cosine_score['bad_english'] = cosine_similarity(sent_matrix,bad_english_emb.mean(0)[None,:])\n",
    "cosine_score.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba42b840-2487-4dd4-9847-5f3877cbe7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"positive_competence\"]=cosine_similarity(sent_matrix,positive_competence_emb.mean(0)[None,:])\n",
    "df[\"negative_competence\"]=cosine_similarity(sent_matrix,negative_competence_emb.mean(0)[None,:])\n",
    "df[\"student_friendly\"]=cosine_similarity(sent_matrix,student_friendly_emb.mean(0)[None,:])\n",
    "df[\"not_student_friendly\"]=cosine_similarity(sent_matrix,not_student_friendly_emb.mean(0)[None,:])\n",
    "df[\"good_english\"]= cosine_similarity(sent_matrix,good_english_emb.mean(0)[None,:])\n",
    "df[\"bad_english\"]=cosine_similarity(sent_matrix,bad_english_emb.mean(0)[None,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e39637f-9e05-470e-987e-309c6bc61ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['Point']==1.0, 'positive_competence'] =df[\"positive_competence\"]+0.05\n",
    "df.loc[df['Point']==1.0, 'student_friendly'] =df[\"student_friendly\"]+0.05\n",
    "df.loc[df['Point']==1.0, 'good_english'] =df[\"good_english\"]+0.05\n",
    "df.loc[df['Point']==1.0, 'negative_competence'] =df[\"negative_competence\"]-0.05\n",
    "df.loc[df['Point']==1.0, 'not_student_friendly'] =df[\"not_student_friendly\"]-0.05\n",
    "df.loc[df['Point']==1.0, 'bad_english'] =df[\"bad_english\"]-0.05\n",
    "df.loc[df['Point']==0.0, 'positive_competence'] =df[\"positive_competence\"]-0.05\n",
    "df.loc[df['Point']==0.0, 'student_friendly'] =df[\"student_friendly\"]-0.05\n",
    "df.loc[df['Point']==0.0, 'good_english'] =df[\"good_english\"]-0.05\n",
    "df.loc[df['Point']==0.0, 'negative_competence'] =df[\"negative_competence\"]+0.05\n",
    "df.loc[df['Point']==0.0, 'not_student_friendly'] =df[\"not_student_friendly\"]+0.05\n",
    "df.loc[df['Point']==0.0, 'bad_english'] =df[\"bad_english\"]+0.05\n",
    "df[\"Competence\"]=0.5+df[\"positive_competence\"]-df[\"negative_competence\"]\n",
    "df[\"Friendly\"]=0.5+df[\"student_friendly\"]-df[\"not_student_friendly\"]\n",
    "df[\"English_Skill\"]=0.5+df[\"good_english\"]-df[\"bad_english\"]\n",
    "df=df.drop(['positive_competence', 'negative_competence',\"good_english\",\"bad_english\",\"student_friendly\",\"not_student_friendly\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06cdb4e-57a7-4ccb-aaf4-10b2a4a2dc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f30f6a7-7484-44a4-858a-a43a6ae9a372",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3=df2[df2.Text == \"-\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8b601c-21bf-4036-9435-b82f29893a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3[\"Competence\"]=\"\"\n",
    "df3[\"Friendly\"]=\"\"\n",
    "df3[\"English_Skill\"]=\"\"\n",
    "df3.loc[df3['Point']==1.0, 'Competence'] =0.600\n",
    "df3.loc[df3['Point']==1.0, 'Friendly'] =0.600\n",
    "df3.loc[df3['Point']==1.0, 'English_Skill'] =0.600\n",
    "df3.loc[df3['Point']==0.5, 'Competence'] =0.500\n",
    "df3.loc[df3['Point']==0.5, 'Friendly'] =0.500\n",
    "df3.loc[df3['Point']==0.5, 'English_Skill'] =0.500\n",
    "df3.loc[df3['Point']==0.0, 'Competence'] =0.400\n",
    "df3.loc[df3['Point']==0.0, 'Friendly'] =0.400\n",
    "df3.loc[df3['Point']==0.0, 'English_Skill'] =0.400\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec1b442-51e5-46a1-a1f7-b110dfda7582",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.concat([df,df3])\n",
    "df_final[\"Competence\"]=pd.to_numeric(df_final[\"Competence\"])\n",
    "df_final[\"Friendly\"]=pd.to_numeric(df_final[\"Friendly\"])\n",
    "df_final[\"English_Skill\"]=pd.to_numeric(df_final[\"English_Skill\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c91dd04-17dc-41c7-a3ce-b85c5c49d354",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3b753a-641d-42d8-8838-41c31d5b6289",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_group = df_final.groupby([\"Lesson Name\",\"Teacher Name\"]).mean()\n",
    "df_group.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84513675-3774-4eec-a2ac-0d3d88be5bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lessons=pd.read_csv(\"lessons_code.csv\").copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5e0519-2003-4004-8dc5-382abde73fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lessons.loc[df_lessons['Lesson Code'].str.contains(' '), 'Lesson Hours'] = df_lessons['Lesson Date']\n",
    "df_lessons.loc[df_lessons['Lesson Code'].str.contains(' '), 'Lesson Date'] = df_lessons['Teacher Name']\n",
    "df_lessons.loc[df_lessons['Lesson Code'].str.contains(' '), 'Teacher Name'] = '-'\n",
    "df_lessons[\"Lesson Short\"] = df_lessons[\"Lesson Code\"].str.split('.').str[0]\n",
    "df_lessons[\"Lesson Date\"]=df_lessons[\"Lesson Date\"].str[1:]\n",
    "df_lessons[\"Lesson Hours\"]=df_lessons[\"Lesson Hours\"].str[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87be5054-0246-4f08-a8e1-f729228d429b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_lessons.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2c3c73-3295-4648-bc0b-7ea7b4006faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_group = df_group.reset_index(level=-1)\n",
    "df_group.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5979aa-4be1-4429-bd37-8ed31b022552",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_group.rename(columns = {'Lesson Name':'Lesson Shorts'}, inplace = True)\n",
    "df_final.rename(columns = {'Lesson Name':'Lesson Shorts'}, inplace = True)\n",
    "df_group = df_group.reset_index(level=-1)\n",
    "df_group[\"Teacher+Lesson\"]= df_group[\"Teacher Name\"]+\" \"+df_group[\"Lesson Name\"]\n",
    "df_lessons['Lesson Short'] = df_lessons['Lesson Short'].astype(str)\n",
    "df_lessons[\"Teacher+Lesson\"]= df_lessons[\"Teacher Name\"]+\" \"+df_lessons[\"Lesson Short\"]\n",
    "df_group['Teacher+Lesson'] = df_group['Teacher+Lesson'].str.upper()\n",
    "df_group['Teacher Name'] = df_group['Teacher Name'].str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b49bb5e-06e2-4ff1-a93a-b716605a4e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_group.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae4e7dc-9c50-451b-b1d6-0828050b62ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lessons.head(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ac640e-ff3b-4014-9520-db067957bd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_group['Teacher+Lesson'] = df_group['Teacher+Lesson'].str.replace('İ','I')\n",
    "df_group['Teacher+Lesson'] = df_group['Teacher+Lesson'].str.replace('Ş','S')\n",
    "df_group['Teacher+Lesson'] = df_group['Teacher+Lesson'].str.replace('Ö','O')\n",
    "df_group['Teacher+Lesson'] = df_group['Teacher+Lesson'].str.replace('Ü','U')\n",
    "df_group['Teacher+Lesson'] = df_group['Teacher+Lesson'].str.replace('Ç','C')\n",
    "df_group['Teacher+Lesson'] = df_group['Teacher+Lesson'].str.replace('Ğ','G')\n",
    "df_lessons['Teacher+Lesson'] = df_lessons['Teacher+Lesson'].str.replace('İ','I')\n",
    "df_lessons['Teacher+Lesson'] = df_lessons['Teacher+Lesson'].str.replace('Ş','S')\n",
    "df_lessons['Teacher+Lesson'] = df_lessons['Teacher+Lesson'].str.replace('Ö','O')\n",
    "df_lessons['Teacher+Lesson'] = df_lessons['Teacher+Lesson'].str.replace('Ü','U')\n",
    "df_lessons['Teacher+Lesson'] = df_lessons['Teacher+Lesson'].str.replace('Ç','C')\n",
    "df_lessons['Teacher+Lesson'] = df_lessons['Teacher+Lesson'].str.replace('Ğ','G')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd3043f-57ed-4373-ba4c-ceb318578a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = pd.merge(df_lessons, df_group, on='Teacher+Lesson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352c6a51-3265-4dc0-ae36-3f262f3edcfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7008bcf3-0a80-44c4-a3ac-6666af371328",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = df_merged.drop([\"Teacher Name_y\",\"Lesson Name_y\",\"Teacher+Lesson\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb70634a-9c55-423c-8641-e02834c0192a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.rename(columns = {'Lesson Name_x':'Lesson Name'}, inplace = True)\n",
    "df_merged.rename(columns = {'Teacher Name_x':'Teacher Name'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c433f8-1c38-459f-819f-bb63a15234e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35658fb6-614e-46f9-9f23-3109d96282ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter('final_excel_son2.xlsx') as writer:\n",
    "    df_merged.to_excel(writer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
